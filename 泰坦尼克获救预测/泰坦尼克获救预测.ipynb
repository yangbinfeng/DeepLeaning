{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "891/891 [==============================] - 1s 741us/step - loss: 0.7342 - acc: 0.4545\n",
      "Epoch 2/50\n",
      "891/891 [==============================] - 0s 100us/step - loss: 0.7318 - acc: 0.5297\n",
      "Epoch 3/50\n",
      "891/891 [==============================] - 0s 61us/step - loss: 0.7055 - acc: 0.6341\n",
      "Epoch 4/50\n",
      "891/891 [==============================] - 0s 104us/step - loss: 0.6983 - acc: 0.6745\n",
      "Epoch 5/50\n",
      "891/891 [==============================] - 0s 74us/step - loss: 0.6804 - acc: 0.6723\n",
      "Epoch 6/50\n",
      "891/891 [==============================] - 0s 72us/step - loss: 0.6905 - acc: 0.6723\n",
      "Epoch 7/50\n",
      "891/891 [==============================] - 0s 65us/step - loss: 0.6870 - acc: 0.6958\n",
      "Epoch 8/50\n",
      "891/891 [==============================] - 0s 111us/step - loss: 0.6577 - acc: 0.6914\n",
      "Epoch 9/50\n",
      "891/891 [==============================] - 0s 70us/step - loss: 0.6555 - acc: 0.6745\n",
      "Epoch 10/50\n",
      "891/891 [==============================] - 0s 82us/step - loss: 0.6575 - acc: 0.6835\n",
      "Epoch 11/50\n",
      "891/891 [==============================] - 0s 75us/step - loss: 0.6494 - acc: 0.6824\n",
      "Epoch 12/50\n",
      "891/891 [==============================] - 0s 99us/step - loss: 0.6226 - acc: 0.6992\n",
      "Epoch 13/50\n",
      "891/891 [==============================] - 0s 114us/step - loss: 0.6322 - acc: 0.6813\n",
      "Epoch 14/50\n",
      "891/891 [==============================] - 0s 122us/step - loss: 0.6299 - acc: 0.6880\n",
      "Epoch 15/50\n",
      "891/891 [==============================] - 0s 110us/step - loss: 0.6319 - acc: 0.6835\n",
      "Epoch 16/50\n",
      "891/891 [==============================] - 0s 86us/step - loss: 0.6214 - acc: 0.6768\n",
      "Epoch 17/50\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.6042 - acc: 0.690 - 0s 98us/step - loss: 0.6138 - acc: 0.6857\n",
      "Epoch 18/50\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.6201 - acc: 0.685 - 0s 118us/step - loss: 0.6196 - acc: 0.6813\n",
      "Epoch 19/50\n",
      "891/891 [==============================] - 0s 78us/step - loss: 0.6148 - acc: 0.6790\n",
      "Epoch 20/50\n",
      "891/891 [==============================] - 0s 83us/step - loss: 0.6036 - acc: 0.6902\n",
      "Epoch 21/50\n",
      "891/891 [==============================] - 0s 66us/step - loss: 0.6051 - acc: 0.6846\n",
      "Epoch 22/50\n",
      "891/891 [==============================] - 0s 67us/step - loss: 0.6018 - acc: 0.6902\n",
      "Epoch 23/50\n",
      "891/891 [==============================] - 0s 111us/step - loss: 0.5980 - acc: 0.6667\n",
      "Epoch 24/50\n",
      "891/891 [==============================] - 0s 76us/step - loss: 0.5900 - acc: 0.6835\n",
      "Epoch 25/50\n",
      "891/891 [==============================] - 0s 87us/step - loss: 0.5904 - acc: 0.6925\n",
      "Epoch 26/50\n",
      "891/891 [==============================] - 0s 97us/step - loss: 0.5813 - acc: 0.6970\n",
      "Epoch 27/50\n",
      "891/891 [==============================] - 0s 96us/step - loss: 0.5827 - acc: 0.6958\n",
      "Epoch 28/50\n",
      "891/891 [==============================] - 0s 101us/step - loss: 0.5687 - acc: 0.7003\n",
      "Epoch 29/50\n",
      "891/891 [==============================] - 0s 92us/step - loss: 0.5702 - acc: 0.7003\n",
      "Epoch 30/50\n",
      "891/891 [==============================] - 0s 113us/step - loss: 0.5678 - acc: 0.7026\n",
      "Epoch 31/50\n",
      "891/891 [==============================] - 0s 72us/step - loss: 0.5638 - acc: 0.6981\n",
      "Epoch 32/50\n",
      "891/891 [==============================] - 0s 64us/step - loss: 0.5725 - acc: 0.6925\n",
      "Epoch 33/50\n",
      "891/891 [==============================] - 0s 68us/step - loss: 0.5637 - acc: 0.7003\n",
      "Epoch 34/50\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.5565 - acc: 0.7003\n",
      "Epoch 35/50\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.5578 - acc: 0.6970\n",
      "Epoch 36/50\n",
      "891/891 [==============================] - 0s 95us/step - loss: 0.5501 - acc: 0.7127\n",
      "Epoch 37/50\n",
      "891/891 [==============================] - 0s 92us/step - loss: 0.5483 - acc: 0.7116\n",
      "Epoch 38/50\n",
      "891/891 [==============================] - 0s 67us/step - loss: 0.5445 - acc: 0.7149\n",
      "Epoch 39/50\n",
      "891/891 [==============================] - 0s 87us/step - loss: 0.5539 - acc: 0.7183: 0s - loss: 0.5525 - acc: 0.724\n",
      "Epoch 40/50\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.5447 - acc: 0.7228\n",
      "Epoch 41/50\n",
      "891/891 [==============================] - 0s 97us/step - loss: 0.5378 - acc: 0.7239\n",
      "Epoch 42/50\n",
      "891/891 [==============================] - 0s 126us/step - loss: 0.5364 - acc: 0.7306\n",
      "Epoch 43/50\n",
      "891/891 [==============================] - 0s 117us/step - loss: 0.5394 - acc: 0.7250\n",
      "Epoch 44/50\n",
      "891/891 [==============================] - 0s 87us/step - loss: 0.5298 - acc: 0.7430\n",
      "Epoch 45/50\n",
      "891/891 [==============================] - 0s 105us/step - loss: 0.5418 - acc: 0.7306\n",
      "Epoch 46/50\n",
      "891/891 [==============================] - 0s 87us/step - loss: 0.5408 - acc: 0.7217\n",
      "Epoch 47/50\n",
      "891/891 [==============================] - 0s 104us/step - loss: 0.5448 - acc: 0.7306\n",
      "Epoch 48/50\n",
      "891/891 [==============================] - 0s 97us/step - loss: 0.5258 - acc: 0.7441\n",
      "Epoch 49/50\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.5278 - acc: 0.7407\n",
      "Epoch 50/50\n",
      "891/891 [==============================] - 0s 91us/step - loss: 0.5296 - acc: 0.7520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1c87c668>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "\n",
    "data = pd.read_csv(\"/Users/yangbinfeng/Downloads/python入门/泰坦尼克获救预测/train.csv\")\n",
    "\n",
    "data = data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp',\n",
    "       'Parch', 'Fare', 'Cabin', 'Embarked']]\n",
    "data['Age']=data['Age'].fillna(data['Age'].median())\n",
    "data['Age'] = preprocessing.scale(data['Age'])\n",
    "data['Fare'] = preprocessing.scale(data['Fare'])\n",
    "data['Cabin']=pd.factorize(data.Cabin)[0]\n",
    "data.fillna(0,inplace=True)\n",
    "#data['Sex']=[1 if x==\"male\" else 0 for x in data.Sex]\n",
    "data['male']=np.array(data['Sex']=='male').astype(np.int32)\n",
    "data['female']=np.array(data['Sex']=='female').astype(np.int32)\n",
    "del data['Sex']\n",
    "\n",
    "data['p1']=np.array(data['Pclass']==1).astype(np.int32)\n",
    "data['p2']=np.array(data['Pclass']==2).astype(np.int32)\n",
    "data['p3']=np.array(data['Pclass']==3).astype(np.int32)\n",
    "del data['Pclass']\n",
    "\n",
    "data['e1']=np.array(data['Embarked']=='S').astype(np.int32)\n",
    "data['e2']=np.array(data['Embarked']=='C').astype(np.int32)\n",
    "data['e3']=np.array(data['Embarked']=='Q').astype(np.int32)\n",
    "del data['Embarked']\n",
    "\n",
    "data_train = data[['male','female', 'Age', 'SibSp','Parch', 'Fare', 'Cabin', 'p1','p2','p3','e1','e2','e3']]\n",
    "data_target = data['Survived'].values.reshape(len(data),1)\n",
    "\n",
    "inputs=Input(shape=(13,))\n",
    "x=Dense(13,activation='relu')(inputs)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dropout(0.5)(x)\n",
    "predictions=Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data_train, data_target,\n",
    "          batch_size=100,epochs = 50,verbose=1,shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "891/891 [==============================] - 1s 1ms/step - loss: 1.0323 - acc: 0.4108\n",
      "Epoch 2/150\n",
      "891/891 [==============================] - 0s 69us/step - loss: 0.8124 - acc: 0.5208\n",
      "Epoch 3/150\n",
      "891/891 [==============================] - 0s 83us/step - loss: 0.9680 - acc: 0.6094\n",
      "Epoch 4/150\n",
      "891/891 [==============================] - 0s 72us/step - loss: 0.7624 - acc: 0.6644\n",
      "Epoch 5/150\n",
      "891/891 [==============================] - 0s 60us/step - loss: 0.7829 - acc: 0.6543\n",
      "Epoch 6/150\n",
      "891/891 [==============================] - 0s 83us/step - loss: 0.8276 - acc: 0.6510\n",
      "Epoch 7/150\n",
      "891/891 [==============================] - 0s 85us/step - loss: 0.7348 - acc: 0.6599\n",
      "Epoch 8/150\n",
      "891/891 [==============================] - 0s 84us/step - loss: 0.7538 - acc: 0.6678\n",
      "Epoch 9/150\n",
      "891/891 [==============================] - 0s 86us/step - loss: 0.6714 - acc: 0.6790\n",
      "Epoch 10/150\n",
      "891/891 [==============================] - 0s 91us/step - loss: 0.7181 - acc: 0.6846\n",
      "Epoch 11/150\n",
      "891/891 [==============================] - 0s 78us/step - loss: 0.6845 - acc: 0.6745\n",
      "Epoch 12/150\n",
      "891/891 [==============================] - 0s 80us/step - loss: 0.6878 - acc: 0.6768\n",
      "Epoch 13/150\n",
      "891/891 [==============================] - 0s 99us/step - loss: 0.6827 - acc: 0.6577\n",
      "Epoch 14/150\n",
      "891/891 [==============================] - 0s 94us/step - loss: 0.6716 - acc: 0.6622\n",
      "Epoch 15/150\n",
      "891/891 [==============================] - 0s 81us/step - loss: 0.6529 - acc: 0.6779\n",
      "Epoch 16/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.6677 - acc: 0.668 - 0s 110us/step - loss: 0.6624 - acc: 0.6712\n",
      "Epoch 17/150\n",
      "891/891 [==============================] - 0s 112us/step - loss: 0.6361 - acc: 0.6779\n",
      "Epoch 18/150\n",
      "891/891 [==============================] - 0s 98us/step - loss: 0.6707 - acc: 0.6655\n",
      "Epoch 19/150\n",
      "891/891 [==============================] - 0s 85us/step - loss: 0.6569 - acc: 0.6689\n",
      "Epoch 20/150\n",
      "891/891 [==============================] - 0s 100us/step - loss: 0.6375 - acc: 0.6790\n",
      "Epoch 21/150\n",
      "891/891 [==============================] - 0s 104us/step - loss: 0.6319 - acc: 0.6813\n",
      "Epoch 22/150\n",
      "891/891 [==============================] - 0s 102us/step - loss: 0.5938 - acc: 0.6880\n",
      "Epoch 23/150\n",
      "891/891 [==============================] - 0s 124us/step - loss: 0.6874 - acc: 0.6655\n",
      "Epoch 24/150\n",
      "891/891 [==============================] - 0s 80us/step - loss: 0.6089 - acc: 0.6914\n",
      "Epoch 25/150\n",
      "891/891 [==============================] - 0s 75us/step - loss: 0.6324 - acc: 0.6768\n",
      "Epoch 26/150\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.6334 - acc: 0.6723\n",
      "Epoch 27/150\n",
      "891/891 [==============================] - 0s 82us/step - loss: 0.6354 - acc: 0.6801\n",
      "Epoch 28/150\n",
      "891/891 [==============================] - 0s 109us/step - loss: 0.6323 - acc: 0.6756\n",
      "Epoch 29/150\n",
      "891/891 [==============================] - 0s 85us/step - loss: 0.6195 - acc: 0.6756\n",
      "Epoch 30/150\n",
      "891/891 [==============================] - 0s 88us/step - loss: 0.6099 - acc: 0.6779\n",
      "Epoch 31/150\n",
      "891/891 [==============================] - 0s 72us/step - loss: 0.5967 - acc: 0.6880\n",
      "Epoch 32/150\n",
      "891/891 [==============================] - 0s 98us/step - loss: 0.6058 - acc: 0.6801\n",
      "Epoch 33/150\n",
      "891/891 [==============================] - 0s 87us/step - loss: 0.6297 - acc: 0.6824\n",
      "Epoch 34/150\n",
      "891/891 [==============================] - 0s 105us/step - loss: 0.5977 - acc: 0.6914\n",
      "Epoch 35/150\n",
      "891/891 [==============================] - 0s 135us/step - loss: 0.5915 - acc: 0.6768\n",
      "Epoch 36/150\n",
      "891/891 [==============================] - 0s 84us/step - loss: 0.6266 - acc: 0.6768\n",
      "Epoch 37/150\n",
      "891/891 [==============================] - 0s 92us/step - loss: 0.5952 - acc: 0.6869\n",
      "Epoch 38/150\n",
      "891/891 [==============================] - 0s 95us/step - loss: 0.6023 - acc: 0.6790\n",
      "Epoch 39/150\n",
      "891/891 [==============================] - 0s 106us/step - loss: 0.6109 - acc: 0.6756\n",
      "Epoch 40/150\n",
      "891/891 [==============================] - 0s 92us/step - loss: 0.5881 - acc: 0.6846\n",
      "Epoch 41/150\n",
      "891/891 [==============================] - 0s 77us/step - loss: 0.6034 - acc: 0.6846\n",
      "Epoch 42/150\n",
      "891/891 [==============================] - 0s 107us/step - loss: 0.5786 - acc: 0.6869\n",
      "Epoch 43/150\n",
      "891/891 [==============================] - 0s 90us/step - loss: 0.5780 - acc: 0.6891\n",
      "Epoch 44/150\n",
      "891/891 [==============================] - 0s 97us/step - loss: 0.5846 - acc: 0.6880\n",
      "Epoch 45/150\n",
      "891/891 [==============================] - 0s 96us/step - loss: 0.5775 - acc: 0.6914\n",
      "Epoch 46/150\n",
      "891/891 [==============================] - 0s 85us/step - loss: 0.5814 - acc: 0.6880\n",
      "Epoch 47/150\n",
      "891/891 [==============================] - 0s 70us/step - loss: 0.5739 - acc: 0.6947\n",
      "Epoch 48/150\n",
      "891/891 [==============================] - 0s 55us/step - loss: 0.5619 - acc: 0.7015\n",
      "Epoch 49/150\n",
      "891/891 [==============================] - 0s 57us/step - loss: 0.5795 - acc: 0.6970\n",
      "Epoch 50/150\n",
      "891/891 [==============================] - 0s 71us/step - loss: 0.5842 - acc: 0.6857\n",
      "Epoch 51/150\n",
      "891/891 [==============================] - 0s 77us/step - loss: 0.5817 - acc: 0.6891\n",
      "Epoch 52/150\n",
      "891/891 [==============================] - 0s 97us/step - loss: 0.5569 - acc: 0.7059\n",
      "Epoch 53/150\n",
      "891/891 [==============================] - 0s 95us/step - loss: 0.5690 - acc: 0.6992\n",
      "Epoch 54/150\n",
      "891/891 [==============================] - 0s 77us/step - loss: 0.5637 - acc: 0.6981\n",
      "Epoch 55/150\n",
      "891/891 [==============================] - 0s 92us/step - loss: 0.5617 - acc: 0.7059\n",
      "Epoch 56/150\n",
      "891/891 [==============================] - 0s 89us/step - loss: 0.5660 - acc: 0.6936\n",
      "Epoch 57/150\n",
      "891/891 [==============================] - 0s 91us/step - loss: 0.5684 - acc: 0.7003\n",
      "Epoch 58/150\n",
      "891/891 [==============================] - 0s 84us/step - loss: 0.5589 - acc: 0.7116\n",
      "Epoch 59/150\n",
      "891/891 [==============================] - 0s 86us/step - loss: 0.5604 - acc: 0.7093\n",
      "Epoch 60/150\n",
      "891/891 [==============================] - 0s 76us/step - loss: 0.5577 - acc: 0.7149\n",
      "Epoch 61/150\n",
      "891/891 [==============================] - 0s 90us/step - loss: 0.5638 - acc: 0.6958\n",
      "Epoch 62/150\n",
      "891/891 [==============================] - 0s 88us/step - loss: 0.5528 - acc: 0.7172\n",
      "Epoch 63/150\n",
      "891/891 [==============================] - 0s 67us/step - loss: 0.5470 - acc: 0.7183\n",
      "Epoch 64/150\n",
      "891/891 [==============================] - 0s 67us/step - loss: 0.5543 - acc: 0.7071\n",
      "Epoch 65/150\n",
      "891/891 [==============================] - 0s 60us/step - loss: 0.5496 - acc: 0.7082\n",
      "Epoch 66/150\n",
      "891/891 [==============================] - 0s 88us/step - loss: 0.5502 - acc: 0.7138\n",
      "Epoch 67/150\n",
      "891/891 [==============================] - 0s 69us/step - loss: 0.5490 - acc: 0.7037\n",
      "Epoch 68/150\n",
      "891/891 [==============================] - 0s 90us/step - loss: 0.5475 - acc: 0.7149\n",
      "Epoch 69/150\n",
      "891/891 [==============================] - 0s 76us/step - loss: 0.5368 - acc: 0.7295\n",
      "Epoch 70/150\n",
      "891/891 [==============================] - 0s 78us/step - loss: 0.5606 - acc: 0.7082\n",
      "Epoch 71/150\n",
      "891/891 [==============================] - 0s 86us/step - loss: 0.5663 - acc: 0.7138\n",
      "Epoch 72/150\n",
      "891/891 [==============================] - 0s 111us/step - loss: 0.5478 - acc: 0.7228\n",
      "Epoch 73/150\n",
      "891/891 [==============================] - 0s 109us/step - loss: 0.5426 - acc: 0.7250\n",
      "Epoch 74/150\n",
      "891/891 [==============================] - 0s 88us/step - loss: 0.5389 - acc: 0.7228: 0s - loss: 0.5415 - acc: 0.718\n",
      "Epoch 75/150\n",
      "891/891 [==============================] - 0s 87us/step - loss: 0.5458 - acc: 0.7284\n",
      "Epoch 76/150\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.5482 - acc: 0.7194\n",
      "Epoch 77/150\n",
      "891/891 [==============================] - 0s 99us/step - loss: 0.5325 - acc: 0.7340\n",
      "Epoch 78/150\n",
      "891/891 [==============================] - 0s 122us/step - loss: 0.5291 - acc: 0.7284\n",
      "Epoch 79/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.5382 - acc: 0.725 - 0s 91us/step - loss: 0.5372 - acc: 0.7228\n",
      "Epoch 80/150\n",
      "891/891 [==============================] - 0s 100us/step - loss: 0.5348 - acc: 0.7295\n",
      "Epoch 81/150\n",
      "891/891 [==============================] - 0s 111us/step - loss: 0.5273 - acc: 0.7396\n",
      "Epoch 82/150\n",
      "891/891 [==============================] - 0s 94us/step - loss: 0.5219 - acc: 0.7486\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891/891 [==============================] - 0s 103us/step - loss: 0.5294 - acc: 0.7419\n",
      "Epoch 84/150\n",
      "891/891 [==============================] - 0s 94us/step - loss: 0.5340 - acc: 0.7385\n",
      "Epoch 85/150\n",
      "891/891 [==============================] - 0s 108us/step - loss: 0.5320 - acc: 0.7396\n",
      "Epoch 86/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.5320 - acc: 0.752 - 0s 99us/step - loss: 0.5306 - acc: 0.7441\n",
      "Epoch 87/150\n",
      "891/891 [==============================] - 0s 126us/step - loss: 0.5257 - acc: 0.7374\n",
      "Epoch 88/150\n",
      "891/891 [==============================] - 0s 109us/step - loss: 0.5333 - acc: 0.7329\n",
      "Epoch 89/150\n",
      "891/891 [==============================] - 0s 119us/step - loss: 0.5224 - acc: 0.7452\n",
      "Epoch 90/150\n",
      "891/891 [==============================] - 0s 136us/step - loss: 0.5245 - acc: 0.7419 0s - loss: 0.5289 - acc: 0.742\n",
      "Epoch 91/150\n",
      "891/891 [==============================] - 0s 96us/step - loss: 0.5156 - acc: 0.7486\n",
      "Epoch 92/150\n",
      "891/891 [==============================] - 0s 118us/step - loss: 0.5413 - acc: 0.7396\n",
      "Epoch 93/150\n",
      "891/891 [==============================] - 0s 110us/step - loss: 0.5096 - acc: 0.7598\n",
      "Epoch 94/150\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.5093 - acc: 0.7531\n",
      "Epoch 95/150\n",
      "891/891 [==============================] - 0s 101us/step - loss: 0.5082 - acc: 0.7497\n",
      "Epoch 96/150\n",
      "891/891 [==============================] - 0s 113us/step - loss: 0.5082 - acc: 0.7520\n",
      "Epoch 97/150\n",
      "891/891 [==============================] - 0s 86us/step - loss: 0.5079 - acc: 0.7553\n",
      "Epoch 98/150\n",
      "891/891 [==============================] - 0s 79us/step - loss: 0.5102 - acc: 0.7508\n",
      "Epoch 99/150\n",
      "891/891 [==============================] - 0s 99us/step - loss: 0.5125 - acc: 0.7531\n",
      "Epoch 100/150\n",
      "891/891 [==============================] - 0s 102us/step - loss: 0.5096 - acc: 0.7520\n",
      "Epoch 101/150\n",
      "891/891 [==============================] - 0s 99us/step - loss: 0.5020 - acc: 0.7587\n",
      "Epoch 102/150\n",
      "891/891 [==============================] - 0s 115us/step - loss: 0.4986 - acc: 0.7609\n",
      "Epoch 103/150\n",
      "891/891 [==============================] - 0s 118us/step - loss: 0.5013 - acc: 0.7565\n",
      "Epoch 104/150\n",
      "891/891 [==============================] - 0s 109us/step - loss: 0.5013 - acc: 0.7621\n",
      "Epoch 105/150\n",
      "891/891 [==============================] - 0s 117us/step - loss: 0.5164 - acc: 0.7621\n",
      "Epoch 106/150\n",
      "891/891 [==============================] - 0s 122us/step - loss: 0.4963 - acc: 0.7621\n",
      "Epoch 107/150\n",
      "891/891 [==============================] - 0s 116us/step - loss: 0.5130 - acc: 0.7576\n",
      "Epoch 108/150\n",
      "891/891 [==============================] - 0s 102us/step - loss: 0.5012 - acc: 0.7688\n",
      "Epoch 109/150\n",
      "891/891 [==============================] - 0s 127us/step - loss: 0.5058 - acc: 0.7621\n",
      "Epoch 110/150\n",
      "891/891 [==============================] - 0s 131us/step - loss: 0.4960 - acc: 0.7722\n",
      "Epoch 111/150\n",
      "891/891 [==============================] - 0s 119us/step - loss: 0.4938 - acc: 0.7800\n",
      "Epoch 112/150\n",
      "891/891 [==============================] - 0s 123us/step - loss: 0.4890 - acc: 0.7800\n",
      "Epoch 113/150\n",
      "891/891 [==============================] - 0s 80us/step - loss: 0.4953 - acc: 0.7666\n",
      "Epoch 114/150\n",
      "891/891 [==============================] - 0s 86us/step - loss: 0.4876 - acc: 0.7823\n",
      "Epoch 115/150\n",
      "891/891 [==============================] - 0s 88us/step - loss: 0.4804 - acc: 0.7890\n",
      "Epoch 116/150\n",
      "891/891 [==============================] - 0s 81us/step - loss: 0.4915 - acc: 0.7778\n",
      "Epoch 117/150\n",
      "891/891 [==============================] - 0s 117us/step - loss: 0.5008 - acc: 0.7778\n",
      "Epoch 118/150\n",
      "891/891 [==============================] - 0s 136us/step - loss: 0.4887 - acc: 0.7901\n",
      "Epoch 119/150\n",
      "891/891 [==============================] - 0s 92us/step - loss: 0.5071 - acc: 0.7744\n",
      "Epoch 120/150\n",
      "891/891 [==============================] - 0s 96us/step - loss: 0.4884 - acc: 0.7901\n",
      "Epoch 121/150\n",
      "891/891 [==============================] - 0s 69us/step - loss: 0.4866 - acc: 0.7969\n",
      "Epoch 122/150\n",
      "891/891 [==============================] - 0s 71us/step - loss: 0.4869 - acc: 0.7980\n",
      "Epoch 123/150\n",
      "891/891 [==============================] - 0s 87us/step - loss: 0.4805 - acc: 0.7980\n",
      "Epoch 124/150\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.4795 - acc: 0.7856\n",
      "Epoch 125/150\n",
      "891/891 [==============================] - 0s 100us/step - loss: 0.4909 - acc: 0.7890\n",
      "Epoch 126/150\n",
      "891/891 [==============================] - 0s 108us/step - loss: 0.4789 - acc: 0.7890\n",
      "Epoch 127/150\n",
      "891/891 [==============================] - 0s 123us/step - loss: 0.4766 - acc: 0.8036\n",
      "Epoch 128/150\n",
      "891/891 [==============================] - 0s 118us/step - loss: 0.4822 - acc: 0.7969\n",
      "Epoch 129/150\n",
      "891/891 [==============================] - 0s 88us/step - loss: 0.4822 - acc: 0.7980\n",
      "Epoch 130/150\n",
      "891/891 [==============================] - 0s 72us/step - loss: 0.5152 - acc: 0.7767\n",
      "Epoch 131/150\n",
      "891/891 [==============================] - 0s 99us/step - loss: 0.4783 - acc: 0.7980\n",
      "Epoch 132/150\n",
      "891/891 [==============================] - 0s 94us/step - loss: 0.4818 - acc: 0.7957\n",
      "Epoch 133/150\n",
      "891/891 [==============================] - 0s 118us/step - loss: 0.4714 - acc: 0.8025\n",
      "Epoch 134/150\n",
      "891/891 [==============================] - 0s 125us/step - loss: 0.4744 - acc: 0.7980\n",
      "Epoch 135/150\n",
      "891/891 [==============================] - 0s 93us/step - loss: 0.4737 - acc: 0.7935\n",
      "Epoch 136/150\n",
      "891/891 [==============================] - 0s 134us/step - loss: 0.4744 - acc: 0.8025\n",
      "Epoch 137/150\n",
      "891/891 [==============================] - 0s 90us/step - loss: 0.4834 - acc: 0.7879\n",
      "Epoch 138/150\n",
      "891/891 [==============================] - 0s 74us/step - loss: 0.4761 - acc: 0.7957\n",
      "Epoch 139/150\n",
      "891/891 [==============================] - ETA: 0s - loss: 0.4601 - acc: 0.812 - 0s 113us/step - loss: 0.4643 - acc: 0.8092\n",
      "Epoch 140/150\n",
      "891/891 [==============================] - 0s 111us/step - loss: 0.4675 - acc: 0.7957\n",
      "Epoch 141/150\n",
      "891/891 [==============================] - 0s 98us/step - loss: 0.4740 - acc: 0.7946\n",
      "Epoch 142/150\n",
      "891/891 [==============================] - 0s 101us/step - loss: 0.4704 - acc: 0.8025\n",
      "Epoch 143/150\n",
      "891/891 [==============================] - 0s 101us/step - loss: 0.4713 - acc: 0.8002\n",
      "Epoch 144/150\n",
      "891/891 [==============================] - 0s 118us/step - loss: 0.4741 - acc: 0.8025\n",
      "Epoch 145/150\n",
      "891/891 [==============================] - 0s 101us/step - loss: 0.4728 - acc: 0.8002\n",
      "Epoch 146/150\n",
      "891/891 [==============================] - 0s 109us/step - loss: 0.4691 - acc: 0.8036\n",
      "Epoch 147/150\n",
      "891/891 [==============================] - 0s 130us/step - loss: 0.4621 - acc: 0.8238\n",
      "Epoch 148/150\n",
      "891/891 [==============================] - 0s 88us/step - loss: 0.4690 - acc: 0.8047\n",
      "Epoch 149/150\n",
      "891/891 [==============================] - 0s 104us/step - loss: 0.4674 - acc: 0.7935\n",
      "Epoch 150/150\n",
      "891/891 [==============================] - 0s 111us/step - loss: 0.4706 - acc: 0.8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a20980860>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import preprocessing\n",
    "\n",
    "data = pd.read_csv(\"/Users/yangbinfeng/Downloads/python入门/泰坦尼克获救预测/train.csv\")\n",
    "\n",
    "data = data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp',\n",
    "       'Parch', 'Fare', 'Cabin', 'Embarked']]\n",
    "data['Age']=data['Age'].fillna(data['Age'].median())\n",
    "data['Age'] = preprocessing.scale(data['Age'])\n",
    "data['Fare'] = preprocessing.scale(data['Fare'])\n",
    "data['Cabin']=pd.factorize(data.Cabin)[0]\n",
    "data.fillna(0,inplace=True)\n",
    "#data['Sex']=[1 if x==\"male\" else 0 for x in data.Sex]\n",
    "data['male']=np.array(data['Sex']=='male').astype(np.int32)\n",
    "data['female']=np.array(data['Sex']=='female').astype(np.int32)\n",
    "del data['Sex']\n",
    "\n",
    "data['p1']=np.array(data['Pclass']==1).astype(np.int32)\n",
    "data['p2']=np.array(data['Pclass']==2).astype(np.int32)\n",
    "data['p3']=np.array(data['Pclass']==3).astype(np.int32)\n",
    "del data['Pclass']\n",
    "\n",
    "data['e1']=np.array(data['Embarked']=='S').astype(np.int32)\n",
    "data['e2']=np.array(data['Embarked']=='C').astype(np.int32)\n",
    "data['e3']=np.array(data['Embarked']=='Q').astype(np.int32)\n",
    "del data['Embarked']\n",
    "\n",
    "data_train = data[['male','female', 'Age', 'SibSp','Parch', 'Fare', 'Cabin', 'p1','p2','p3','e1','e2','e3']]\n",
    "data_target = data['Survived'].values.reshape(len(data),1)\n",
    "\n",
    "inputs=Input(shape=(13,))\n",
    "x=Dense(13,activation='relu')(inputs)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "x=Dropout(0.5)(x)\n",
    "predictions=Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data_train, data_target,\n",
    "          batch_size=100,epochs =150,verbose=1,shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
